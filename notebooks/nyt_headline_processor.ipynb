{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A notebook for testing headline processing\n",
    "But this version used the OLD format of the NYT headlines, which were from news-api. Since then, NYT headliens were no longer served by NewsAPI so it needs a separate method. Then, sometime between January and April 2020, newsapi started serving from nytimes.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field Mapping\n",
    "\n",
    "## Bylines\n",
    "The author field from newsapi is a mess. Each source has a different style. Note: the source for all of these comes through as \"ABC News\", so there will be duplicates from AP.\n",
    "\n",
    "From abc-news:\n",
    "- PHILIP MARCELO Associated Press\n",
    "- Thomas Smith\n",
    "- ANDREW DALTON AP Entertainment Writer\n",
    "- Benjamin Siegel, Adia Robinson\n",
    "\n",
    "From associated-press:\n",
    "- By RONALD BLUM AP Baseball\n",
    "- By JOHNSON LAI and ELAINE KURTENBACH Associated Press\n",
    "- By JEFF HAMPTON The Virginian-Pilot\n",
    "- By DANNY MCARTHUR, Daily Journal\n",
    "- By The Associated Press\n",
    "- null (empty)\n",
    "\n",
    "From fox-news:\n",
    "- Joseph Wulfsohn\n",
    "- L. Brent Bozell III, Tim Graham\n",
    "- Associated Press\n",
    "- null (empty)\n",
    "\n",
    "From msnbc (OK, all of these are \"watch\" urls, maybe this isn't what I needed):\n",
    "- MSNBC.com\n",
    "\n",
    "From the-washington-post:\n",
    "- Juan Zamorano | AP\n",
    "- Associated Press\n",
    "- Carolyn Hax\n",
    "- Sudarsan Raghavan, Loveday Morris\n",
    "\n",
    "From the-new-york-times api original might be:\n",
    "- By Caroline Biggs\n",
    "- By The New York Times\n",
    "- null, ['person'] is empty list\n",
    "\n",
    "```\n",
    "\"byline\": {\n",
    "  \"original\": \"By Caroline Biggs\",\n",
    "  \"person\": [\n",
    "    {\n",
    "      \"firstname\": \"Caroline\",\n",
    "      \"middlename\": null,\n",
    "      \"lastname\": \"Biggs\",\n",
    "      \"qualifier\": null,\n",
    "      \"title\": null,\n",
    "      \"role\": \"reported\",\n",
    "      \"organization\": \"\",\n",
    "      \"rank\": 1\n",
    "    }\n",
    "  ],\n",
    "  \"organization\": null\n",
    "}\n",
    "```\n",
    "\n",
    "For NYT, there is occasionally a different print headline than main."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NYT stores output in `data['response']['docs']`\n",
    "\n",
    "| newsapi | nyt-api |\n",
    "|---|---|\n",
    "| author | `data['response']['docs'][i]['byline']['original']` |\n",
    "| title | `data['response']['docs'][i]['headline']['main']` |\n",
    "| description | `data['response']['docs'][i]['abstract']` |\n",
    "| url | `data['response']['docs'][i]['web_url']` |\n",
    "| urlToImage | https://static01.nyt.com/ + `data['response]['docs'][i]['multimedia'][0]['url']` |\n",
    "| publishedAt | `data['response']['docs'][i]['pub_date']` |\n",
    "| content |`data['response']['docs'][i]['lead_paragraph']` |\n",
    "| source.id | 'nytimes' |\n",
    "| source.name | 'The New York Times' |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(base_dir, begin_date, end_date):\n",
    "\n",
    "    n_days = int((end_date - begin_date).total_seconds()/60/60/24)\n",
    "    date_list = [begin_date + timedelta(days=x) for x in range(n_days+1)]\n",
    "    \n",
    "    search_strs = []\n",
    "    \n",
    "    for date in date_list:\n",
    "        search_strs.append(date.strftime('%Y-%m-%d'))\n",
    "\n",
    "    filenames=[]\n",
    "\n",
    "    for search_str in search_strs:\n",
    "        \n",
    "        filenames += sorted(glob.glob(os.path.join(base_dir, '*' + search_str + '*.json')))\n",
    "        \n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_nytsource_on_date(date, source='the-new-york-times'):\n",
    "\n",
    "    source_dir = f\"/home/will/Projects/headliner/datastore/raw/{source}/\"\n",
    "    out_dir = f\"/home/will/Projects/headliner/datastore/processed/{source}/\"\n",
    "    \n",
    "    filenames = find_files(source_dir, date, date)\n",
    "\n",
    "    def concat_files(file_list):\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for filename in file_list:\n",
    "            \n",
    "            with open(filename, \"r\") as file:\n",
    "                to_add = json.load(file)\n",
    "                \n",
    "            authors = []\n",
    "            titles = []\n",
    "            descriptions = []\n",
    "            urls = []\n",
    "            urlToImages = []\n",
    "            publishedAts = []\n",
    "            contents = []\n",
    "\n",
    "            for item in to_add['response']['docs']:\n",
    "                authors.append(item['byline']['original'])\n",
    "                titles.append(item['headline']['main'])\n",
    "                descriptions.append(item['abstract'])\n",
    "                urls.append(item['web_url'])\n",
    "                publishedAts.append(item['pub_date'])\n",
    "                contents.append(item['lead_paragraph'])\n",
    "\n",
    "                if len(item['multimedia']) > 0:\n",
    "                    urlToImages.append('https://static01.nyt.com/' + item['multimedia'][0]['url'])\n",
    "                else:\n",
    "                    urlToImages.append(None)\n",
    "                    \n",
    "            to_add = pd.DataFrame(\n",
    "                {\n",
    "                    'author': authors,\n",
    "                    'title': titles,\n",
    "                    'description': descriptions,\n",
    "                    'url': urls,\n",
    "                    'urlToImage': urlToImages,\n",
    "                    'publishedAt': publishedAts,\n",
    "                    'content': contents\n",
    "                }\n",
    "            )\n",
    "            to_add['source.id'] = source\n",
    "            to_add['source.name'] = 'The New York Times'\n",
    "                    \n",
    "            results.append(to_add)\n",
    "            \n",
    "        return pd.concat(results, ignore_index=True)\n",
    "    \n",
    "    concatted = concat_files(filenames)\n",
    "    concatted.to_csv(os.path.join(out_dir, f\"{source}-{date.strftime('%Y-%m-%d')}.csv\"), index=False)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'response'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-30f81936da94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocess_nytsource_on_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2020\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m29\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-d7f5afa93b28>\u001b[0m in \u001b[0;36mprocess_nytsource_on_date\u001b[0;34m(date, source)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mconcatted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mconcatted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{source}-{date.strftime('%Y-%m-%d')}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d7f5afa93b28>\u001b[0m in \u001b[0;36mconcat_files\u001b[0;34m(file_list)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_add\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'response'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'docs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0mauthors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'byline'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'original'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mtitles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'headline'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'main'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'response'"
     ]
    }
   ],
   "source": [
    "process_nytsource_on_date(datetime(2020,1,29,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = find_files(, date, date)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
